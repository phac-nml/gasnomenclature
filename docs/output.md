# phac-nml/gasnomenclature: Output

## Introduction

This document describes the output produced by the pipeline.

The directories listed below will be created in the results directory after the pipeline has finished. All paths are relative to the top-level results directory.

- append: Contains reference MLST profile and cluster address files if additional databases were provided by the user.
- call: The cluster addresses from the [genomic_address_service](https://github.com/phac-nml/genomic_address_service).
- cluster: The cluster file required by GAS_call.
- distances: Distances between genomes from [profile_dists](https://github.com/phac-nml/profile_dists).
- filter: The cluster addresses from only the query samples.
- locidex: The merged MLST JSON files for reference and query samples, and their error reports for MLST profiles changed.
- pipeline_info: Information about the pipeline's execution
- write: A CSV of the sample names to be used for each MLST (profiles) for locidex

The IRIDA Next-compliant JSON output file will be named `iridanext.output.json.gz` and will be written to the top-level of the results directory. This file is compressed using GZIP and conforms to the [IRIDA Next JSON output specifications](https://github.com/phac-nml/pipeline-standards#42-irida-next-json).

## Pipeline overview

The pipeline is built using [Nextflow](https://www.nextflow.io/) and processes data using the following steps:

- [Locidex merge](#locidex-merge) - Merges MLST profile JSON files into a single profiles file for reference and query samples. Performs a validation check on the samplesheet inputs to ensure that the sampleID precisely matches the MLST JSON key and enforces necessary changes where discrepancies are found. When split into multiple processes a concatation occurs after.
- [Append profiles](#append-profiles) - Appends additional MLST profile information to reference samples if provided by user.
- [Profile dists](#profile-dists) - Computes pairwise distances between genomes using MLST allele differences.
- [Cluster file](#cluster-file) - Generates the expected_clusters.txt file from reference sample addresses for use in GAS_call.
- [Append clusters](#append-clusters) - Appends additional cluster information to reference samples if provided by user.
- [GAS call](#gas-call) - Generates hierarchical cluster addresses.
- [Filter query](#filter-query) - Filters and generates a csv file containing only the cluster addresses for query samples.
- [IRIDA Next Output](#irida-next-output) - Generates a JSON output file that is compliant with IRIDA Next
- [Pipeline information](#pipeline-information) - Report metrics generated during the workflow execution
- [Write](#write) - Takes the input samplesheet and converts to CSV to be passed to locidex merge.

### Locidex merge

<details markdown="1">
<summary>Output files</summary>

- `locidex/merge/`
  - reference samples:
    - `reference/merged_ref/profile.tsv`
    - `reference/merged_ref/MLST_error_report.csv`
  - query samples:
    - `reference/merged_query/profile.tsv`
    - `reference/merged_query/MLST_error_report.csv`
- `locidex/concat/`
  - reference samples:
    - `reference/merged_ref/profile_concat_ref.tsv`
    - `reference/merged_ref/MLST_error_report_concat_ref.csv`
  - query samples:
    - `reference/merged_query/profile_concat_query.tsv`
    - `reference/merged_query/MLST_error_report_concat_query.csv`

</details>

### Append Profiles

<details markdown="1">
<summary>Output files</summary>

- `append/`
  - profiles: `profiles_ref.tsv`

</details>

### Profile Dists

<details markdown="1">
<summary>Output files</summary>

- `distances/`
  - Mapping allele identifiers to integers: `allele_map.json`
  - The query MLST profiles: `query_profile.text`
  - The reference MLST profiles: `ref_profile.text`
  - The computed distances based on MLST allele differences: `results.text`
  - Information on the profile_dists run: `run.json`

</details>

### Cluster File

<details markdown="1">
<summary>Output files</summary>

- `cluster/`
  - `expected_clusters.txt`

</details>

### Append Clusters

<details markdown="1">
<summary>Output files</summary>

- `append/`
  - clusters: `reference_clusters.tsv`

</details>

### GAS call

<details markdown="1">
<summary>Output files</summary>

- `call/`
  - The computed cluster addresses: `clusters.text`
  - Information on the GAS mcluster run: `run.json`
  - Thesholds used to compute cluster addresses: `thresholds.json`

</details>

### Filter Query

<details markdown="1">
<summary>Output files</summary>

- `filter/`
  - `new_addresses.tsv`

</details>

### Pipeline information

<details markdown="1">
<summary>Output files</summary>

- `pipeline_info/`
  - Reports generated by Nextflow: `execution_report.html`, `execution_timeline.html`, `execution_trace.txt` and `pipeline_dag.dot`/`pipeline_dag.svg`.
  - Reports generated by the pipeline: `pipeline_report.html`, `pipeline_report.txt` and `software_versions.yml`. The `pipeline_report*` files will only be present if the `--email` / `--email_on_fail` parameter's are used when running the pipeline.
  - Reformatted samplesheet files used as input to the pipeline: `samplesheet.valid.csv`.
  - Parameters used by the pipeline run: `params.json`.

</details>

[Nextflow](https://www.nextflow.io/docs/latest/tracing.html) provides excellent functionality for generating various reports relevant to the running and execution of the pipeline. This will allow you to troubleshoot errors with the running of the pipeline, and also provide you with other information such as launch commands, run times and resource usage.

### Write

<details markdown="1">
<summary>Output files</summary>

- `write/`
  - `results.csv`
