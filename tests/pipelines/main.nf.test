nextflow_pipeline {

    name "Integration test of nomenclature assignment pipeline"
    script "main.nf"

    test("Small-scale test of full pipeline"){
        tag "pipeline_success"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet1.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/reference/merged_ref/profile.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/merged_query/profile.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/expected_clusters.txt")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/test_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.samples
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."address" == "1.1.3"
        }
    }

    test("Small-scale test of full pipeline with scaled distances"){
        tag "pipeline_success_scaled"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet1.csv"
                outdir = "results"

                pd_distm = "scaled"
                gm_thresholds = "50,20,0"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/reference/merged_ref/profile.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile_scaled1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/merged_query/profile.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile_scaled2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_dists_scaled.txt")
            assert actual_distances.text == expected_distances.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_scaled.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/scaled_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.samples
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."address" == "1.2.3"
        }
    }


    test("Small-scale test of full pipeline with multiple queries"){
        tag "pipeline_success_multiple_queries"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiple_queries.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/reference/merged_ref/profile.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile_queries1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/merged_query/profile.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile_queries2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_queries_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/expected_clusters.txt")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_queries.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/queries_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.samples
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_metadata.size() == 2
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.containsKey("sampleN")

            assert iridanext_metadata.sampleQ."address" == "1.1.3"
            assert iridanext_metadata.sampleN."address" == "2.2.4"
        }
    }

    test("Small-scale test of full pipeline with gzipped MLST JSON"){
        tag "Gzipped_MLST_JSON"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_gzip.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/test_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.samples
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."address" == "1.1.3"
        }
    }

    test("Testing when query and reference sample IDs are mismatched with MLST JSON file keys"){
        // IDs in the sample sheet and IDs in the individual MLST JSON files will not match.
        // This tests the pipelines ability to handle and correct for this problem.

        tag "mismatched_IDs"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-mismatched_IDs.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for reference samples
            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample2,[\'sample7\'],sample2 ID and JSON key in sample7.mlst.json DO NOT MATCH. The 'sample7' key in sample7.mlst.json has been forcefully changed to 'sample2': User should manually check input files to ensure correctness.")
            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sampleR,[\'sampleF\'],sampleR ID and JSON key in sampleF.mlst.json DO NOT MATCH. The 'sampleF' key in sampleF.mlst.json has been forcefully changed to 'sampleR': User should manually check input files to ensure correctness.")

            // Check filter_query csv file
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")
            assert lines.contains("sampleR\tsampleR\t2.2.4")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/mismatched_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.samples
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_metadata.size() == 2
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.containsKey("sampleR")

            assert iridanext_metadata.sampleQ."address" == "1.1.3"
            assert iridanext_metadata.sampleR."address" == "2.2.4"
        }
    }

    test("Testing data removal in MLST JSON with a matching sampleID key."){
        // There are multiple sample entries (keys) in the MLST JSON and one of them matches the sampleID.
        // This test evaluates the pipeline's ability to address this issue by removing keys that do not match the sampleID.

        tag "multiple_keys_with_matching_ID"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiple_keys.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples
            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains('sample3,"[\'extra_key\', \'sample3\']","MLST JSON file (sample3_multiplekeys.mlst.json) contains multiple keys: [\'extra_key\', \'sample3\']. The MLST JSON file has been modified to retain only the \'sample3\' entry"')

            // Check filtered query csv results
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/multiplekeys_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_samples.size() == 1
            assert iridanext_samples.path == ['locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv']

            assert iridanext_metadata.size() == 1
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."address" == "1.1.3"
        }
    }

    test("Testing the removal of data in MLST JSON with no sampleID match."){
        // There are multiple sample entries (keys) in the MLST JSON and none of them match the sampleID..
        // This test ensures the pipeline can handle and resolve this issue by retaining only the first JSON key entry and renaming it to match the sampleID.

        tag "multiple_keys_without_matching_ID"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiplekeys_nomatch.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples
            lines = path("$launchDir/results/locidex/merge/reference/merged_ref/MLST_error_report.csv").readLines()
            assert lines.contains('sample3,"[\'extra_key\', \'sample4\']",No key in the MLST JSON file (sample3_multiplekeys_nomatch.mlst.json) matches the specified sample ID \'sample3\'. The first key \'extra_key\' has been forcefully changed to \'sample3\' and all other keys have been removed.')

            // Check filtered query csv results
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/multiplekeys_iridanext.output.json").json

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_samples = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_samples.size() == 1
            assert iridanext_samples.path == ["locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv"]

            assert iridanext_metadata.size() == 1
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."address" == "1.1.3"
        }
    }

    test("Testing when provided MLST JSON file(s) are empty."){
        tag "empty_JSON"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_emptyJSON.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.failed
            assert (workflow.stdout =~ /sample2_empty.mlst.json is missing the 'profile' section or is completely empty!/).find()
        }
    }

    test("Testing when sample_name column is included on input"){
        // For integration in IRIDA-Next there needs to be an option to have the input file include a sample_name column

        tag "add-sample-name"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-sample_name.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples based on sample_name swap with sample
            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_1,[\'sampleQ\'],sample_1 ID and JSON key in sampleQ.mlst.json DO NOT MATCH. The 'sampleQ' key in sampleQ.mlst.json has been forcefully changed to 'sample_1': User should manually check input files to ensure correctness.")

            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_2,[\'sample1\'],sample_2 ID and JSON key in sample1.mlst.json DO NOT MATCH. The 'sample1' key in sample1.mlst.json has been forcefully changed to 'sample_2': User should manually check input files to ensure correctness.")

            lines = path("$launchDir/results/locidex/concat/reference/concat_ref/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_2_sample2,[\'sample2\'],sample_2_sample2 ID and JSON key in sample2.mlst.json DO NOT MATCH. The 'sample2' key in sample2.mlst.json has been forcefully changed to 'sample_2_sample2': User should manually check input files to ensure correctness.")

            // Check filter_query csv file
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsample_1\t1.1.3")
            assert lines.contains("sampleR\tsample4\t2.2.4")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").json == path("$baseDir/tests/data/irida/sample_name_add_iridanext.output.json").json

        }
    }
}
