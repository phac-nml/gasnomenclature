nextflow_pipeline {

    name "Integration test of nomenclature assignment pipeline"
    script "main.nf"

    test("Small-scale test of full pipeline"){
        tag "pipeline_success"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet1.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/ref/profile_1.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/expected_clusters.txt")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/test_iridanext.output.json").json.files.global.sort { it.path}
            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
        }
    }

    test("Small-scale test of full pipeline with scaled distances"){
        tag "pipeline_success_scaled"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet1.csv"
                outdir = "results"

                pd_distm = "scaled"
                gm_thresholds = "50,20,0"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/ref/profile_1.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile_scaled1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile_scaled2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_dists_scaled.txt")
            assert actual_distances.text == expected_distances.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_scaled.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/scaled_iridanext.output.json").json.files.global.sort { it.path}
            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.2.3"
        }
    }


    test("Small-scale test of full pipeline with multiple queries"){
        tag "pipeline_success_multiple_queries"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiple_queries.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check merged profiles
            def actual_profile_ref = path("$launchDir/results/locidex/merge/ref/profile_1.tsv")
            def expected_profile_tsv = path("$baseDir/tests/data/profiles/expected-profile_queries1.tsv")
            assert actual_profile_ref.text == expected_profile_tsv.text

            // Check query profiles
            def actual_profile_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv")
            def expected_profile_query_tsv = path("$baseDir/tests/data/profiles/expected-profile_queries2.tsv")
            assert actual_profile_query.text == expected_profile_query_tsv.text

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_queries_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/expected_clusters.txt")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_queries.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/queries_iridanext.output.json").json.files.global.sort { it.path}

            assert iridanext_metadata.size() == 2
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.containsKey("sampleN")

            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
            assert iridanext_metadata.sampleN."genomic_address_name" == "1.1.3"
        }
    }

    test("Small-scale test of full pipeline with gzipped MLST JSON"){
        tag "Gzipped_MLST_JSON"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_gzip.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/test_iridanext.output.json").json.files.global.sort { it.path}

            assert iridanext_metadata.size() == 1 && iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
        }
    }

    test("Testing when query and reference sample IDs are mismatched with MLST JSON file keys"){
        // IDs in the sample sheet and IDs in the individual MLST JSON files will not match.
        // This tests the pipelines ability to handle and correct for this problem.

        tag "mismatched_IDs"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-mismatched_IDs.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for reference samples
            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample2,[\'sample7\'],sample2 ID and JSON key in sample7.mlst.json DO NOT MATCH. The 'sample7' key in sample7.mlst.json has been forcefully changed to 'sample2': User should manually check input files to ensure correctness.")
            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sampleR,[\'sampleF\'],sampleR ID and JSON key in sampleF.mlst.json DO NOT MATCH. The 'sampleF' key in sampleF.mlst.json has been forcefully changed to 'sampleR': User should manually check input files to ensure correctness.")

            // Check filter_query csv file
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")
            assert lines.contains("sampleR\tsampleR\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/mismatched_iridanext.output.json").json.files.global.sort { it.path}

            assert iridanext_metadata.size() == 2
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.containsKey("sampleR")

            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
            assert iridanext_metadata.sampleR."genomic_address_name" == "1.1.3"

        }
    }

    test("Testing data removal in MLST JSON with a matching sampleID key."){
        // There are multiple sample entries (keys) in the MLST JSON and one of them matches the sampleID.
        // This test evaluates the pipeline's ability to address this issue by removing keys that do not match the sampleID.

        tag "multiple_keys_with_matching_ID"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiple_keys.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples
            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains('sample3,"[\'extra_key\', \'sample3\']","MLST JSON file (sample3_multiplekeys.mlst.json) contains multiple keys: [\'extra_key\', \'sample3\']. The MLST JSON file has been modified to retain only the \'sample3\' entry"')

            // Check filtered query csv results
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/multiplekeys_iridanext.output.json").json.files.global.sort { it.path}

            assert iridanext_metadata.size() == 1
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
        }
    }

    test("Testing the removal of data in MLST JSON with no sampleID match."){
        // There are multiple sample entries (keys) in the MLST JSON and none of them match the sampleID..
        // This test ensures the pipeline can handle and resolve this issue by retaining only the first JSON key entry and renaming it to match the sampleID.

        tag "multiple_keys_without_matching_ID"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-multiplekeys_nomatch.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results.txt")
            assert actual_calls.text == expected_calls.text

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples
            lines = path("$launchDir/results/locidex/merge/ref/MLST_error_report_1.csv").readLines()
            assert lines.contains('sample3,"[\'extra_key\', \'sample4\']",No key in the MLST JSON file (sample3_multiplekeys_nomatch.mlst.json) matches the specified sample ID \'sample3\'. The first key \'extra_key\' has been forcefully changed to \'sample3\' and all other keys have been removed.')

            // Check filtered query csv results
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsampleQ\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/multiplekeys_iridanext.output.json").json.files.global.sort { it.path}

            assert iridanext_metadata.size() == 1
            assert iridanext_metadata.containsKey("sampleQ")
            assert iridanext_metadata.sampleQ."genomic_address_name" == "1.1.3"
        }
    }

    test("Testing when provided MLST JSON file(s) are empty."){
        tag "empty_JSON"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_emptyJSON.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.failed
            assert (workflow.stdout =~ /sample2_empty.mlst.json is missing the 'profile' section or is completely empty!/).find()
        }
    }

    test("Testing when sample_name column is included on input"){
        // For integration in IRIDA-Next there needs to be an option to have the input file include a sample_name column

        tag "add-sample-name"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-sample_name.csv"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check outputs
            def lines = []

            // Ensure that the error_reports are generated for query and reference samples based on sample_name swap with sample
            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_1,[\'sampleQ\'],sample_1 ID and JSON key in sampleQ.mlst.json DO NOT MATCH. The 'sampleQ' key in sampleQ.mlst.json has been forcefully changed to 'sample_1': User should manually check input files to ensure correctness.")

            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_2,[\'sample1\'],sample_2 ID and JSON key in sample1.mlst.json DO NOT MATCH. The 'sample1' key in sample1.mlst.json has been forcefully changed to 'sample_2': User should manually check input files to ensure correctness.")

            lines = path("$launchDir/results/locidex/concat/reference/MLST_error_report_concat_ref.csv").readLines()
            assert lines.contains("sample_2_sample2,[\'sample2\'],sample_2_sample2 ID and JSON key in sample2.mlst.json DO NOT MATCH. The 'sample2' key in sample2.mlst.json has been forcefully changed to 'sample_2_sample2': User should manually check input files to ensure correctness.")

            // Check filter_query csv file
            lines = path("$launchDir/results/filter/new_addresses.tsv").readLines()
            assert lines.contains("sampleQ\tsample_1\t1.1.3")
            assert lines.contains("sampleR\tsample4\t1.1.3")

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.sort { it.path} == path("$baseDir/tests/data/irida/sample_name_add_iridanext.output.json").json.files.global.sort { it.path}
        }
    }

    test("Testing when batch size is used for LOCIDEX_MERGE"){
        // Downstream of LOCIDEX_MERGE, the batch size is used to split the input into smaller chunks.
        // This is useful for large datasets to increase parallelism and reduce memory usage.

        tag "batch-size"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-batchsize.csv"
                outdir = "results"
                batch_size = 1
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check that LOCIDEX_MERGE was called with the correct batch size
            // Profiles for reference samples
            def lines1 = path("$launchDir/results/locidex/merge/ref/profile_1.tsv").readLines()
            assert lines1.contains("sampleQ\t1\t2\t1")
            def lines2 = path("$launchDir/results/locidex/merge/ref/profile_2.tsv").readLines()
            assert lines2.contains("sampleP\t1\t1\t1")
            def lines3 = path("$launchDir/results/locidex/merge/ref/profile_3.tsv").readLines()
            assert lines3.contains("sample2\t1\t1\t1")
            def lines4 = path("$launchDir/results/locidex/merge/ref/profile_4.tsv").readLines()
            assert lines4.contains("sample3\t1\t1\t2")
            // Profiles for query samples (same as the equivalent reference sample)
            def lines1_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv").readLines()
            assert lines1_query == lines1

            def lines2_query = path("$launchDir/results/locidex/merge/query/profile_2.tsv").readLines()
            assert lines2_query == lines2

            // Error reports
            // Only error report for sampleP should have content to check`
            def error_report = path("$launchDir/results/locidex/merge/ref/MLST_error_report_2.csv").readLines()
            assert error_report.contains("sampleP,[\'sample1\'],sampleP ID and JSON key in sample1.mlst.json DO NOT MATCH. The 'sample1' key in sample1.mlst.json has been forcefully changed to 'sampleP': User should manually check input files to ensure correctness.")
            // Error report for query sampleP should be the same as the reference sample
            def error_report_query = path("$launchDir/results/locidex/merge/query/MLST_error_report_2.csv").readLines()
            assert error_report_query == error_report
        }
    }


    test("No addresses in sample sheet"){
        // The data is based off the GAS walkthrough here:
        // https://github.com/phac-nml/genomic_address_service/blob/b440df37e56bd07e8661a14407de82bed4944fc4/docs/overview.md#gas-call-clustering-new-samples
        tag "pipeline_no_addresses_in_samplesheet"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_walkthrough.csv"
                db_profiles = "$baseDir/tests/data/profiles/profiles_walkthrough.tsv"
                db_clusters = "$baseDir/tests/data/clusters/cluster_walkthrough.tsv"
                gm_thresholds = "5,3,0"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Merged Profiles: Reference
            def profile_reference = path("$launchDir/results/locidex/merge/ref/profile_1.tsv")
            assert profile_reference.text.contains("sample_id\tl1\tl2\tl3\tl4\tl5\tl6\tl7\tl8")
            assert profile_reference.text.contains("E\t1\t2\t3\t1\t1\t1\t2\t1")
            assert profile_reference.text.contains("F\t2\t2\t1\t1\t1\t1\t1\t3")
            assert profile_reference.text.split("\n").size() == 3

            // Merged Profiles: Query
            def profile_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv")
            assert profile_query.text.contains("sample_id\tl1\tl2\tl3\tl4\tl5\tl6\tl7\tl8")
            assert profile_query.text.contains("E\t1\t2\t3\t1\t1\t1\t2\t1")
            assert profile_query.text.contains("F\t2\t2\t1\t1\t1\t1\t1\t3")
            assert profile_query.text.split("\n").size() == 3

            // Check computed pairwise distances
            def pairwise_distances = path("$launchDir/results/distances/results.text")
            assert pairwise_distances.text.contains("query_id\tref_id\tdist")
            assert pairwise_distances.text.contains("E\tE\t0")
            assert pairwise_distances.text.contains("E\tA\t3")
            assert pairwise_distances.text.contains("E\tB\t4")
            assert pairwise_distances.text.contains("E\tC\t4")
            assert pairwise_distances.text.contains("E\tF\t4")
            assert pairwise_distances.text.contains("E\tD\t8")
            assert pairwise_distances.text.contains("F\tF\t0")
            assert pairwise_distances.text.contains("F\tB\t3")
            assert pairwise_distances.text.contains("F\tA\t4")
            assert pairwise_distances.text.contains("F\tE\t4")
            assert pairwise_distances.text.contains("F\tC\t5")
            assert pairwise_distances.text.contains("F\tD\t6")
            assert pairwise_distances.text.split("\n").size() == 13

            // Verify cluster file
            def cluster = path("$launchDir/results/cluster/clusters.tsv")
            assert cluster.text.contains("id\taddress")
            assert cluster.text.split("\n").size() == 1

            // Check called clusters
            def called_clusters = path("$launchDir/results/call/Called/results.text")
            assert called_clusters.text.contains("id\taddress")
            assert called_clusters.text.contains("A\t1.1.1")
            assert called_clusters.text.contains("B\t1.1.2")
            assert called_clusters.text.contains("C\t1.2.3")
            assert called_clusters.text.contains("D\t2.3.4")
            assert called_clusters.text.contains("E\t1.4.5")
            assert called_clusters.text.contains("F\t1.5.6")
            assert called_clusters.text.split("\n").size() == 7

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.findAll { it.path == "pipeline_info/software_versions.yml" }.size() == 1
            assert iridanext_global.findAll { it.path == "locidex/concat/query/MLST_error_report_concat_query.csv" }.size() == 1
            assert iridanext_global.findAll { it.path == "locidex/concat/reference/MLST_error_report_concat_ref.csv" }.size() == 1

            assert iridanext_metadata.size() == 2

            assert iridanext_metadata.containsKey("E")
            assert iridanext_metadata.E.genomic_address_name == "1.4.5"

            assert iridanext_metadata.containsKey("F")
            assert iridanext_metadata.F.genomic_address_name == "1.5.6"
        }
    }

    test("Large gzipped profiles and clusters files"){
        // The data is partially based off the GAS walkthrough here:
        // https://github.com/phac-nml/genomic_address_service/blob/b440df37e56bd07e8661a14407de82bed4944fc4/docs/overview.md#gas-call-clustering-new-samples
        tag "pipeline_large_gzip_profiles_clusters"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet_walkthrough.csv"
                db_profiles = "$baseDir/tests/data/profiles/large.tsv.gz"
                db_clusters = "$baseDir/tests/data/clusters/large.tsv.gz"
                gm_thresholds = "5,3,0"
                outdir = "results"
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Merged Profiles: Reference
            def profile_reference = path("$launchDir/results/locidex/merge/ref/profile_1.tsv")
            assert profile_reference.text.contains("sample_id\tl1\tl2\tl3\tl4\tl5\tl6\tl7\tl8")
            assert profile_reference.text.contains("E\t1\t2\t3\t1\t1\t1\t2\t1")
            assert profile_reference.text.contains("F\t2\t2\t1\t1\t1\t1\t1\t3")
            assert profile_reference.text.split("\n").size() == 3

            // Merged Profiles: Query
            def profile_query = path("$launchDir/results/locidex/merge/query/profile_1.tsv")
            assert profile_query.text.contains("sample_id\tl1\tl2\tl3\tl4\tl5\tl6\tl7\tl8")
            assert profile_query.text.contains("E\t1\t2\t3\t1\t1\t1\t2\t1")
            assert profile_query.text.contains("F\t2\t2\t1\t1\t1\t1\t1\t3")
            assert profile_query.text.split("\n").size() == 3

            // Check computed pairwise distances
            def pairwise_distances = path("$launchDir/results/distances/results.text")
            assert pairwise_distances.text.contains("query_id\tref_id\tdist")
            assert pairwise_distances.text.contains("E\tE\t0")
            assert pairwise_distances.text.contains("E\tA\t3")
            assert pairwise_distances.text.contains("E\tB\t4")
            assert pairwise_distances.text.contains("E\tC\t4")
            assert pairwise_distances.text.contains("E\tF\t4")
            assert pairwise_distances.text.contains("E\tD\t8")
            assert pairwise_distances.text.contains("F\tF\t0")
            assert pairwise_distances.text.contains("F\tB\t3")
            assert pairwise_distances.text.contains("F\tA\t4")
            assert pairwise_distances.text.contains("F\tE\t4")
            assert pairwise_distances.text.contains("F\tC\t5")
            assert pairwise_distances.text.contains("F\tD\t6")
            assert pairwise_distances.text.split("\n").size() == 100013

            // Verify cluster file
            def cluster = path("$launchDir/results/cluster/clusters.tsv")
            assert cluster.text.contains("id\taddress")
            assert cluster.text.split("\n").size() == 1

            // Check called clusters
            def called_clusters = path("$launchDir/results/call/Called/results.text")
            assert called_clusters.text.contains("id\taddress")
            assert called_clusters.text.contains("A\t1.1.1")
            assert called_clusters.text.contains("B\t1.1.2")
            assert called_clusters.text.contains("C\t1.2.3")
            assert called_clusters.text.contains("D\t2.3.4")
            assert called_clusters.text.contains("E\t1.4.5")
            assert called_clusters.text.contains("F\t1.5.6")
            assert called_clusters.text.split("\n").size() == 50007

            // Check IRIDA Next JSON output
            assert path("$launchDir/results/iridanext.output.json").exists()

            def iridanext_json = path("$launchDir/results/iridanext.output.json").json
            def iridanext_global = iridanext_json.files.global
            def iridanext_metadata = iridanext_json.metadata.samples

            assert iridanext_global.findAll { it.path == "pipeline_info/software_versions.yml" }.size() == 1
            assert iridanext_global.findAll { it.path == "locidex/concat/query/MLST_error_report_concat_query.csv" }.size() == 1
            assert iridanext_global.findAll { it.path == "locidex/concat/reference/MLST_error_report_concat_ref.csv" }.size() == 1

            assert iridanext_metadata.size() == 2

            assert iridanext_metadata.containsKey("E")
            assert iridanext_metadata.E.genomic_address_name == "1.4.5"

            assert iridanext_metadata.containsKey("F")
            assert iridanext_metadata.F.genomic_address_name == "1.5.6"
        }
    }
test("Testing for when there are repeat MLST allele files in multiple batches"){
        // Previous versions of the pipeline would fail if there were repeat MLST allele files in the samplesheet.
        tag "repeat-mlst"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-duplicateMLST.csv"
                outdir = "results"
                batch_size = 1
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check that the COPY_FILE process was called for the correct samples
            assert path("$launchDir/results/copy/sample2_sample1.mlst.json").exists()
            assert !path("$launchDir/results/copy/sampleQ_sampleQ.mlst.json").exists()
            assert !path("$launchDir/results/copy/sample1_sample1.mlst.json").exists()
            assert !path("$launchDir/results/copy/sample3_sample3.mlst.json").exists()

            // The merge_tsv file used in renaming the MLST profiles in locidex merge has the right file paths
            def merge_tsv_content = path("$launchDir/results/write/results.csv")
            assert merge_tsv_content.text.split('\n').any { line -> line ==~ /^sample2.*\/sample2_sample1\.mlst\.json$/} // The file path (minus the work directory)

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/clusters_MLST_rename.tsv")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_MLST_rename.text")
            assert actual_calls.text == expected_calls.text
        }
    }

    test("Testing for when there are repeat MLST allele files in one single batch"){
        // Previous versions of the pipeline would fail if there were repeat MLST allele files in the samplesheet.
        tag "repeat-mlst-single-batch"

        when{
            params {
                input = "$baseDir/tests/data/samplesheets/samplesheet-samplename.csv"
                outdir = "results"
                batch_size = 10
            }
        }

        then {
            assert workflow.success
            assert path("$launchDir/results").exists()

            // Check that the COPY_FILE process was called for the correct samples
            assert path("$launchDir/results/copy/sample2_sample1.mlst.json").exists()
            assert !path("$launchDir/results/copy/sampleQ_sampleQ.mlst.json").exists()
            assert !path("$launchDir/results/copy/sample1_sample1.mlst.json").exists()
            assert !path("$launchDir/results/copy/sample3_sample3.mlst.json").exists()

            // The merge_tsv file used in renaming the MLST profiles in locidex merge has the right file paths
            def merge_tsv_content = path("$launchDir/results/write/results.csv")
            assert merge_tsv_content.text.split('\n').any { line -> line ==~ /^sample2.*\/sample2_sample1\.mlst\.json$/} // The file path (minus the work directory)

            // Check computed pairwise distances
            def actual_distances = path("$launchDir/results/distances/results.text")
            def expected_distances = path("$baseDir/tests/data/distances/expected_pairwise_dists.txt")
            assert actual_distances.text == expected_distances.text

            // Verify cluster file
            def actual_cluster = path("$launchDir/results/cluster/clusters.tsv")
            def expected_cluster = path("$baseDir/tests/data/clusters/clusters_MLST_rename.tsv")
            assert actual_cluster.text == expected_cluster.text

            // Check called clusters
            def actual_calls = path("$launchDir/results/call/Called/results.text")
            def expected_calls = path("$baseDir/tests/data/called/expected_results_MLST_rename.text")
            assert actual_calls.text == expected_calls.text
        }
    }
}
